{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from thesis_project.settings import EXPERIMENT1_DIR, EXPERIMENT2_DIR, RESULT_DIR\n",
    "from thesis_project.data_loading import (\n",
    "    construct_spikerates_filename,\n",
    "    load_session_ids,\n",
    "    load_spike_data,\n",
    ")\n",
    "from thesis_project.models.rnn_encoder_only import RNNEncoderOnly\n",
    "from thesis_project.models.transformer_encoder_decoder import TransformerEncoderDecoder\n",
    "from thesis_project.models.transformer_encoder_only import TransformerEncoderOnly\n",
    "from thesis_project.parameter_optimization.nn_optimization import NNOptimization\n",
    "from thesis_project.parameter_optimization.svm_optimization import SVMOptimization\n",
    "from thesis_project.preprocessing.tokenization import SingleWordTokenizer\n",
    "from thesis_project.training.metrics import get_classification_metrics\n",
    "from thesis_project.training.metrics import get_regression_metrics\n",
    "from thesis_project.models import OutputType\n",
    "from thesis_project.training.metrics import get_sequence_classification_metrics\n",
    "from thesis_project.preprocessing.label_preparation import prepare_spikerates_for_session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / test split\n",
    "Generate the train / test split to be used in experiments. \\\n",
    "We create 5 stratified folds but only train on one split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(\n",
    "    k_folds: int = 5, shuffle: bool = True, random_state: int = None\n",
    ") -> dict:\n",
    "\n",
    "    train_test_split = {}\n",
    "\n",
    "    session_ids = load_session_ids(data_dir=EXPERIMENT1_DIR)\n",
    "\n",
    "    for session_id in session_ids:\n",
    "\n",
    "        labels_words, _, _, _ = load_spike_data(\n",
    "            f\"{EXPERIMENT1_DIR}/{session_id}_naming\"\n",
    "        )\n",
    "\n",
    "        kfold = StratifiedKFold(\n",
    "            n_splits=k_folds, shuffle=shuffle, random_state=random_state\n",
    "        )\n",
    "\n",
    "        split = kfold.split(np.zeros(len(labels_words)), y=labels_words)\n",
    "\n",
    "        session_ids = [\n",
    "            {\"train_ids\": train_ids.tolist(), \"test_ids\": test_ids.tolist()}\n",
    "            for train_ids, test_ids in split\n",
    "        ]\n",
    "        train_test_split[session_id] = session_ids\n",
    "\n",
    "    return train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "shuffle = True\n",
    "random_state = None\n",
    "\n",
    "train_test_path = f\"{EXPERIMENT1_DIR}/train_test_split/train_test_split.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment this code to create a new train_test_split\n",
    "\n",
    "# train_test_split = create_train_test_split()\n",
    "\n",
    "# with open(train_test_path, \"w\") as file:\n",
    "#     file.write(json.dumps(train_test_split, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train_test_split\n",
    "\n",
    "with open(train_test_path, \"r\") as file:\n",
    "    train_test_split = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_fold_idx = 0\n",
    "current_fold_split = {\n",
    "    session_id: folds[current_fold_idx]\n",
    "    for session_id, folds in train_test_split.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_ids = list(current_fold_split.keys())\n",
    "limit_to_ids = {\n",
    "    session_id: train_test_ids[\"train_ids\"]\n",
    "    for session_id, train_test_ids in current_fold_split.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train test split for simultaneous training on all session_ids\n",
    "\n",
    "combined_train_test_idx = []\n",
    "\n",
    "current_len = 0\n",
    "\n",
    "session_ids = list(current_fold_split.keys())\n",
    "for session_id in session_ids:\n",
    "\n",
    "    current_train_idx = current_fold_split[session_id][\"train_ids\"]\n",
    "    \n",
    "    combined_train_test_idx.extend([idx + current_len for idx in current_train_idx])\n",
    "    spikerates = prepare_spikerates_for_session(\n",
    "                    session_id=session_id,\n",
    "                    path=EXPERIMENT1_DIR,\n",
    "                    bin_size=50,\n",
    "                    blur_sd=None,\n",
    "                    experiment=\"experiment1\",\n",
    "                )\n",
    "    \n",
    "    current_len += len(spikerates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search\n",
    "svm_optimization_parameters = {\n",
    "    \"model_name\": \"svm\",\n",
    "    \"task_name\": \"clf\",\n",
    "    \"experiment\": \"experiment1\",\n",
    "    \"session_ids\": session_ids,\n",
    "    \"limit_to_ids\": limit_to_ids,\n",
    "    \"preprocessing_methods\": [\"mean_sequence\"],  # , \"flatten\"],\n",
    "    \"label_names\": [\"syncat_labels\", \"semcat_labels\", \"labels_words\"],\n",
    "    \"binning_params\": [{\"bin_size\": 50, \"blur_sd\": None},\n",
    "       {\"bin_size\": 50, \"blur_sd\": 2},\n",
    "       {\"bin_size\": 20, \"blur_sd\": None},\n",
    "       {\"bin_size\": 20, \"blur_sd\": 2}],\n",
    "    \"n_folds\": 5,\n",
    "    \"n_repeats\": 5,\n",
    "    \"search_params\": {\n",
    "        \"kernel\": {\"choice\": [\"linear\", \"rbf\", \"sigmoid\"]},\n",
    "        \"C\": {\"exp\": [10, -1, 3]},\n",
    "        \"gamma\": {\"choice\": [0.1, 0.01, 0.001, 0.0001, \"scale\", 'auto'\n",
    "                             ]}\n",
    "    },\n",
    "    \"optimization_type\": \"random\",\n",
    "    \"data_dir\": f\"{EXPERIMENT1_DIR}\",\n",
    "    \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp1/fold_1\",\n",
    "    \"random_seed\": None,\n",
    "    \"n_random_runs\": 50,\n",
    "    \"metric_dict\": get_classification_metrics()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "svm_optimization = SVMOptimization(**svm_optimization_parameters)\n",
    "svm_optimization.run(output_name=\"svm_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_optimization_parameters = {\n",
    "    \"model_name\": \"rnn\",\n",
    "    \"task_name\": \"clf\",\n",
    "    \"session_ids\": session_ids,\n",
    "    \"limit_to_ids\": limit_to_ids,\n",
    "    \"preprocessing_methods\": [\"mean_sequence\"],\n",
    "    \"label_names\": [\"syncat_labels\", \"semcat_labels\", \"labels_words\"],\n",
    "    \"binning_params\": [{\"bin_size\": 50, \"blur_sd\": None},\n",
    "                        {\"bin_size\": 50, \"blur_sd\": 2},\n",
    "                        {\"bin_size\": 20, \"blur_sd\": None},\n",
    "                        {\"bin_size\": 20, \"blur_sd\": 2}],\n",
    "\n",
    "    \"n_folds\": 5,\n",
    "    \"n_repeats\": 1,\n",
    "    \"search_params\": {\"learning_rate\": (\"exp\", [-1, -5, 10]),\n",
    "                      \"weight_decay\": (\"choice\", [0, 1e-1, 1e-2, 1e-3]),\n",
    "                      \"batch_size\": (\"fixed\", 128)},\n",
    "    \"optimization_type\": \"random\",\n",
    "    \"data_dir\": EXPERIMENT1_DIR,\n",
    "    \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp1/fold_1\",\n",
    "    \"fixed_cv_params\": {\n",
    "        \"loss_function\": cross_entropy,\n",
    "        \"device_name\": \"cuda\",\n",
    "        \"num_epochs\": 100,\n",
    "    },\n",
    "    \"model_params\": {\"device\": (\"fixed\", \"cuda\"),\n",
    "                     \"hidden_size\": (\"choice\", [32, 64, 128, 256]),\n",
    "                      \"dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                \"n_layers\": (\"choice\", [1, 2, 3])},\n",
    "    \"random_seed\": None,\n",
    "    \"n_random_runs\": 20,\n",
    "    \"metric_dict\": get_classification_metrics(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_optimization = NNOptimization(**rnn_optimization_parameters)\n",
    "results = nn_optimization.run(output_name=\"rnn_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_optimization_parameters = {\n",
    "    \"model_name\": \"trf\",\n",
    "    \"task_name\": \"clf\",\n",
    "    \"session_ids\": session_ids,\n",
    "    \"limit_to_ids\": limit_to_ids,\n",
    "    \"preprocessing_methods\": [\"mean_sequence\"],\n",
    "    \"label_names\": [\"syncat_labels\", \"semcat_labels\", \"labels_words\"],\n",
    "    \"binning_params\": [{\"bin_size\": 50, \"blur_sd\": None},\n",
    "                        {\"bin_size\": 50, \"blur_sd\": 2},\n",
    "                        {\"bin_size\": 20, \"blur_sd\": None},\n",
    "                        {\"bin_size\": 20, \"blur_sd\": 2}],\n",
    "    \"n_folds\": 5,\n",
    "    \"n_repeats\": 1,\n",
    "    \"search_params\": {\"learning_rate\": (\"exp\", [-1, -5, 10]),\n",
    "                      \"weight_decay\": (\"choice\", [0, 1e-1, 1e-2, 1e-3]),\n",
    "                      \"batch_size\": (\"fixed\", 64)},\n",
    "    \"optimization_type\": \"random\",\n",
    "    \"data_dir\": EXPERIMENT1_DIR,\n",
    "    \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp1/fold_1\",\n",
    "        \"fixed_cv_params\": {\n",
    "        \"loss_function\": cross_entropy,\n",
    "        \"device_name\": \"cuda\",\n",
    "        \"num_epochs\": 100,\n",
    "    },\n",
    "    \"model_params\": {\"device\": (\"fixed\", \"cuda\"),\n",
    "                     \"hidden_size\": (\"choice\", [32, 64, 128, 256]),\n",
    "                      \"dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                      \"n_layers\": (\"choice\", [1, 2, 3])},\n",
    "    \"random_seed\": None,\n",
    "    \"n_random_runs\": 10,\n",
    "    \"metric_dict\": get_classification_metrics(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_optimization = NNOptimization(**transformer_optimization_parameters)\n",
    "results = nn_optimization.run(output_name=\"trf_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svr_optimization_params():\n",
    "    return {\n",
    "        \"model_name\": \"svm\",\n",
    "        \"task_name\": \"reg\",\n",
    "        \"session_ids\":session_ids,\n",
    "        \"limit_to_ids\": limit_to_ids,\n",
    "        \"preprocessing_methods\": [\"mean_sequence\"],\n",
    "        \"label_names\": [\"labels_words\"],\n",
    "        \"binning_params\": [\n",
    "        {\"bin_size\": 50, \"blur_sd\": None},\n",
    "        {\"bin_size\": 50, \"blur_sd\": 2},\n",
    "        {\"bin_size\": 20, \"blur_sd\": None},\n",
    "        {\"bin_size\": 20, \"blur_sd\": 2}],\n",
    "        \"n_folds\": 5,\n",
    "        \"n_repeats\": 1,\n",
    "        \"search_params\": {\n",
    "            \"estimator__kernel\": {\"choice\": [\"linear\", \"rbf\", \"sigmoid\"]},\n",
    "            \"estimator__C\": {\"exp\": [10, -1, 3]},\n",
    "            \"estimator__gamma\": {\"choice\": [0.1, 0.01, 0.001, 0.0001, \"scale\", 'auto']},\n",
    "        },\n",
    "        \"optimization_type\": \"random\",\n",
    "        \"data_dir\": EXPERIMENT1_DIR,\n",
    "        \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp1/fold_1\",\n",
    "        \"random_seed\": None,\n",
    "        \"n_random_runs\": 30,\n",
    "        \"output_type\": OutputType.REGRESSION,\n",
    "        \"embedding\": \"glove-twitter-25\",\n",
    "        \"metric_dict\": get_regression_metrics(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_optimization = SVMOptimization(**get_svr_optimization_params())\n",
    "results = svr_optimization.run(output_name=\"svm_reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_regression_optimization_parameters = {\n",
    "    \"model_name\": \"rnn\",\n",
    "    \"task_name\": \"reg\",\n",
    "    \"session_ids\": session_ids,\n",
    "    \"limit_to_ids\": limit_to_ids,\n",
    "    \"preprocessing_methods\": [\"mean_sequence\"],\n",
    "    \"label_names\": [\"labels_words\"],\n",
    "    \"binning_params\": [{\"bin_size\": 50, \"blur_sd\": None},\n",
    "                        {\"bin_size\": 50, \"blur_sd\": 2},\n",
    "                        {\"bin_size\": 20, \"blur_sd\": None},\n",
    "                        {\"bin_size\": 20, \"blur_sd\": 2}],\n",
    "    \"n_folds\": 5,\n",
    "    \"n_repeats\": 1,\n",
    "    \"search_params\": {\"learning_rate\": (\"exp\", [-1, -5, 10]),\n",
    "                      \"weight_decay\": (\"choice\", [0, 1e-1, 1e-2, 1e-3]),\n",
    "                      \"batch_size\": (\"fixed\", 128)},\n",
    "    \"optimization_type\": \"random\",\n",
    "    \"data_dir\": EXPERIMENT1_DIR,\n",
    "    \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp1/fold_1\",\n",
    "    \"fixed_cv_params\": {\n",
    "        \"loss_function\": MSELoss(),\n",
    "        \"device_name\": \"cuda\",\n",
    "        \"num_epochs\": 100\n",
    "    },\n",
    "    \"model_params\": {\"device\": (\"fixed\", \"cuda\"),\n",
    "                     \"hidden_size\": (\"choice\", [32, 64, 128, 256]),\n",
    "                      \"dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                \"n_layers\": (\"choice\", [1, 2, 3])},\n",
    "    \"random_seed\": None,\n",
    "    \"output_type\": OutputType.REGRESSION,\n",
    "    \"embedding\": \"glove-twitter-25\",\n",
    "    \"n_random_runs\": 50,\n",
    "    \"metric_dict\": get_regression_metrics()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_optimization = NNOptimization(**rnn_regression_optimization_parameters)\n",
    "results = nn_optimization.run(output_name=\"rnn_reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_regression_optimization_parameters = {\n",
    "    \"model_name\": \"trf\",\n",
    "    \"task_name\": \"reg\",\n",
    "    \"session_ids\": session_ids,\n",
    "    \"limit_to_ids\": limit_to_ids,\n",
    "    \"preprocessing_methods\": [\"mean_sequence\"],\n",
    "    \"label_names\": [\"labels_words\"],\n",
    " \"binning_params\": [{\"bin_size\": 50, \"blur_sd\": None},\n",
    "                        {\"bin_size\": 50, \"blur_sd\": 2},\n",
    "                        {\"bin_size\": 20, \"blur_sd\": None},\n",
    "                        {\"bin_size\": 20, \"blur_sd\": 2}],\n",
    "    \"n_folds\": 5,\n",
    "    \"n_repeats\": 1,\n",
    "    \"search_params\": {\"learning_rate\": (\"exp\", [-1, -5, 10]),\n",
    "                      \"weight_decay\": (\"choice\", [0, 1e-1, 1e-2, 1e-3]),\n",
    "                      \"batch_size\": (\"fixed\", 64)},\n",
    "    \"optimization_type\": \"random\",\n",
    "    \"data_dir\": EXPERIMENT1_DIR,\n",
    "    \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp1/fold_1\",\n",
    "    \"fixed_cv_params\": {\n",
    "        \"loss_function\": MSELoss(),\n",
    "        \"device_name\": \"cuda\",\n",
    "        \"num_epochs\": 100\n",
    "        },\n",
    "    \"model_params\": {\"device\": (\"fixed\", \"cuda\"),\n",
    "                     \"hidden_size\": (\"choice\", [32, 64, 128, 256]),\n",
    "                      \"dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                      \"n_layers\": (\"choice\", [1, 2, 3])},\n",
    "    \"random_seed\": None,\n",
    "    \"n_random_runs\": 5,\n",
    "    \"output_type\": OutputType.REGRESSION,\n",
    "    \"embedding\": \"glove-twitter-25\",\n",
    "    \"metric_dict\": get_regression_metrics()\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_optimization = NNOptimization(**transformer_regression_optimization_parameters)\n",
    "results = nn_optimization.run(output_name=\"trf_reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikerates_path = construct_spikerates_filename(\n",
    "    session_id=\"20240708\",\n",
    "    path=f\"{EXPERIMENT2_DIR}/binned_spikerates\",\n",
    "    bin_size=100,\n",
    "    experiment=\"experiment2\",\n",
    ")\n",
    "\n",
    "sentences_path = f\"{EXPERIMENT2_DIR}/sentences_new.pkl\"\n",
    "\n",
    "with open(spikerates_path, \"rb\") as file:\n",
    "    spikerates = np.load(file, allow_pickle=True)\n",
    "\n",
    "with open(sentences_path, \"rb\") as file:\n",
    "    sentences = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "shuffle = True\n",
    "random_state = None\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=n_folds, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "split = kfold.split(np.zeros(len(sentences)), y=sentences)\n",
    "train_test_split = [\n",
    "    {\"train_ids\": train_ids.tolist(), \"test_ids\": test_ids.tolist()}\n",
    "    for train_ids, test_ids in split\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_path = f\"{EXPERIMENT2_DIR}/train_test_split/train_test_split.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment this code to create a new train_test_split\n",
    "\n",
    "# with open(train_test_path, \"w\") as file:\n",
    "#     file.write(json.dumps(train_test_split, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train_test_split\n",
    "\n",
    "with open(train_test_path, \"r\") as file:\n",
    "    train_test_split = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_to_ids = {\"20240708\": train_test_split[0][\"train_ids\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SingleWordTokenizer()\n",
    "tokenizer_file_path = f\"{EXPERIMENT2_DIR}/single_word_token_dict.json\"\n",
    "\n",
    "# uncomment the following code to create a new tokenizer\n",
    "# the tokenization should be deterministic, storing it in a file for convenience\n",
    "# tokenizer.token_dict_from_samples(sentences)\n",
    "# tokenizer.token_dict_to_file(tokenizer_file_path)\n",
    "\n",
    "tokenizer.token_dict_from_file(tokenizer_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_sequence_classification_optimization_parameters = {\n",
    "    \"model_name\": \"rnn\",\n",
    "    \"task_name\": \"seq_clf\",\n",
    "    \"experiment\": \"experiment2\",\n",
    "    \"session_ids\": [\"20240708\"],\n",
    "    \"limit_to_ids\": limit_to_ids,\n",
    "    \"preprocessing_methods\": [\"mean_sequence\"],\n",
    "    \"label_names\": [\"sentences\"],\n",
    "    \"binning_params\": [{\"bin_size\": 100, \"blur_sd\": None},\n",
    "                       {\"bin_size\": 100, \"blur_sd\": 2}],\n",
    "    \"n_folds\": 5,\n",
    "    \"n_repeats\": 1,\n",
    "    \"search_params\": {\"learning_rate\": (\"exp\", [-1, -5, 10]),\n",
    "                      \"weight_decay\": (\"choice\", [0, 1e-1, 1e-2, 1e-3]),\n",
    "                      \"batch_size\": (\"fixed\", 128)},\n",
    "    \"optimization_type\": \"random\",\n",
    "    \"data_dir\": f\"{EXPERIMENT2_DIR}/binned_spikerates\",\n",
    "    \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp2/fold_1\",\n",
    "    \"fixed_cv_params\": {\n",
    "        \"loss_function\": cross_entropy,\n",
    "        \"device_name\": \"cuda\",\n",
    "        \"num_epochs\": 100\n",
    "    },\n",
    "    \"model_params\": {\"n_labels\": (\"choice\", [tokenizer.n_labels]),\n",
    "                     \"encoder_n_layers\": (\"choice\", [1, 2, 3]),\n",
    "                     \"decoder_n_layers\": (\"choice\", [1]),\n",
    "                     \"encoder_hidden_size\": (\"choice\", [32, 64, 128]),\n",
    "                     \"decoder_hidden_size\": (\"choice\", [None]),\n",
    "                     \"encoder_dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                     \"decoder_dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                     \"device\": (\"choice\", [\"cuda\"]),\n",
    "},\n",
    "    \"random_seed\": None,\n",
    "    \"n_random_runs\": 20,\n",
    "    \"output_type\": OutputType.CLASSIFICATION,\n",
    "    \"metric_dict\": get_sequence_classification_metrics()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_optimization = NNOptimization(**rnn_sequence_classification_optimization_parameters)\n",
    "results = nn_optimization.run(output_name=\"rnn_seq_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_sequence_classification_optimization_parameters = {\n",
    "    \"model_name\": \"trf\",\n",
    "    \"task_name\": \"seq_clf\",\n",
    "    \"experiment\": \"experiment2\",\n",
    "    \"session_ids\": [\"20240708\"],\n",
    "    \"limit_to_ids\": limit_to_ids,\n",
    "    \"preprocessing_methods\": [\"mean_sequence\"],\n",
    "    \"label_names\": [\"sentences\"],\n",
    "    \"binning_params\": [{\"bin_size\": 100, \"blur_sd\": None},\n",
    "                       {\"bin_size\": 100, \"blur_sd\": 2}],\n",
    "    \"n_folds\": 5,\n",
    "    \"n_repeats\": 1,\n",
    "    \"search_params\": {\"learning_rate\": (\"exp\", [-1, -5, 10]),\n",
    "                      \"weight_decay\": (\"choice\", [0, 1e-1, 1e-2, 1e-3]),\n",
    "                      \"batch_size\": (\"fixed\", 64)},\n",
    "    \"optimization_type\": \"random\",\n",
    "    \"data_dir\": f\"{EXPERIMENT2_DIR}/binned_spikerates\",\n",
    "    \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp2/fold_1\",\n",
    "    \"fixed_cv_params\": {\n",
    "        \"loss_function\": cross_entropy,\n",
    "        \"device_name\": \"cuda\",\n",
    "        \"num_epochs\": 100\n",
    "    },\n",
    "    \"model_params\": {#\"n_labels\": (\"choice\", [tokenizer.n_labels]),\n",
    "                     \"encoder_n_layers\": (\"choice\", [1, 2, 3]),\n",
    "                     \"decoder_n_layers\": (\"choice\", [1]),\n",
    "                     \"hidden_size\": (\"choice\", [32, 64, 128]),\n",
    "                     \"dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                     \"device\": (\"choice\", [\"cuda\"]),\n",
    "},\n",
    "    \"random_seed\": None,\n",
    "    \"n_random_runs\": 20,\n",
    "    \"output_type\": OutputType.CLASSIFICATION,\n",
    "    \"metric_dict\": get_sequence_classification_metrics()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_optimization = NNOptimization(\n",
    "            **transformer_sequence_classification_optimization_parameters\n",
    "        )\n",
    "results = nn_optimization.run(output_name=\"trf_seq_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_sequence_regression_optimization_parameters = {\n",
    "    \"model_name\": \"rnn\",\n",
    "    \"task_name\": \"seq_reg\",\n",
    "    \"experiment\": \"experiment2\",\n",
    "    \"session_ids\": [\"20240708\"],\n",
    "    \"limit_to_ids\": limit_to_ids,\n",
    "    \"preprocessing_methods\": [\"mean_sequence\"],\n",
    "    \"label_names\": [\"sentences\"],\n",
    "    \"binning_params\": [{\"bin_size\": 100, \"blur_sd\": None},\n",
    "                       {\"bin_size\": 100, \"blur_sd\": 2}],\n",
    "    \"n_folds\": 5,\n",
    "    \"n_repeats\": 1,\n",
    "    \"search_params\": {\"learning_rate\": (\"exp\", [-1, -5, 10]),\n",
    "                      \"weight_decay\": (\"choice\", [0, 1e-1, 1e-2, 1e-3]),\n",
    "                      \"batch_size\": (\"fixed\", 64)},\n",
    "    \"optimization_type\": \"random\",\n",
    "    \"data_dir\": f\"{EXPERIMENT2_DIR}/binned_spikerates\",\n",
    "    \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp2/fold_1\",\n",
    "    \"fixed_cv_params\": {\n",
    "        \"loss_function\": MSELoss(),\n",
    "        \"device_name\": \"cuda\",\n",
    "        \"num_epochs\": 1\n",
    "    },\n",
    "    \"model_params\": {\"encoder_n_layers\": (\"choice\", [3]),\n",
    "                     \"decoder_n_layers\": (\"choice\", [1]),\n",
    "                     \"encoder_hidden_size\": (\"choice\", [128]),\n",
    "                     \"decoder_hidden_size\": (\"choice\", [None]),\n",
    "                     \"encoder_dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                     \"decoder_dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                     \"device\": (\"choice\", [\"cuda\"])},\n",
    "    \"random_seed\": None,\n",
    "    \"output_type\": OutputType.REGRESSION,\n",
    "    \"embedding\": \"glove-twitter-25\",\n",
    "    \"random_seed\": None,\n",
    "    \"n_random_runs\": 1,\n",
    "    \"metric_dict\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_optimization = NNOptimization(**rnn_sequence_regression_optimization_parameters)\n",
    "results = nn_optimization.run(output_name=\"rnn_seq_reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_sequence_regression_optimization_parameters = {\n",
    "    \"model_name\": \"trf\",\n",
    "    \"task_name\": \"seq_reg\",\n",
    "    \"experiment\": \"experiment2\",\n",
    "    \"session_ids\": [\"20240708\"],\n",
    "    \"limit_to_ids\": limit_to_ids,\n",
    "    \"preprocessing_methods\": [\"mean_sequence\"],\n",
    "    \"label_names\": [\"sentences\"],\n",
    "    \"binning_params\": [{\"bin_size\": 100, \"blur_sd\": None},\n",
    "                       {\"bin_size\": 100, \"blur_sd\": 2}],\n",
    "    \"n_folds\": 5,\n",
    "    \"n_repeats\": 1,\n",
    "    \"search_params\": {\"learning_rate\": (\"exp\", [-1, -5, 10]),\n",
    "                      \"weight_decay\": (\"choice\", [0, 1e-1, 1e-2, 1e-3]),\n",
    "                      \"batch_size\": (\"choice\", [64])},\n",
    "    \"optimization_type\": \"random\",\n",
    "    \"data_dir\": f\"{EXPERIMENT2_DIR}/binned_spikerates\",\n",
    "    \"output_dir\": f\"{RESULT_DIR}/final_results/hyperparameter_optimization/exp2/fold_1\",\n",
    "    \"fixed_cv_params\": {\n",
    "        \"loss_function\": MSELoss(),\n",
    "        \"device_name\": \"cuda\",\n",
    "        \"num_epochs\": 1,\n",
    "    },\n",
    "    \"model_params\": {\"encoder_n_layers\": (\"choice\", [1, 2]),\n",
    "                     \"decoder_n_layers\": (\"choice\", [1]),\n",
    "                     \"hidden_size\": (\"choice\", [32, 64, 128]),\n",
    "                     \"dropout\": (\"uniform\", (0.1, 0.8)),\n",
    "                     \"device\": (\"fixed\", \"cuda\")},\n",
    "    \"random_seed\": None,\n",
    "    \"output_type\": OutputType.REGRESSION,\n",
    "    \"embedding\": \"glove-twitter-25\",\n",
    "    \"n_random_runs\": 1,\n",
    "    \"metric_dict\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 1\n",
    "nn_optimization = NNOptimization(\n",
    "    **transformer_sequence_regression_optimization_parameters\n",
    ")\n",
    "results = nn_optimization.run(output_name=\"trf_seq_reg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
